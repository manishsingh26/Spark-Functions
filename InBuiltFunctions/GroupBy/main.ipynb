{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"groupby\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
      "| airline| flight|source_city|departure_time|stops| arrival_time|destination_city|  class|duration|days_left|price|\n",
      "+--------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
      "|SpiceJet|SG-8709|      Delhi|       Evening| zero|        Night|          Mumbai|Economy|    null|        1| 5953|\n",
      "|SpiceJet|SG-8157|      Delhi| Early_Morning| zero|      Morning|          Mumbai|Economy|    null|        1| 5953|\n",
      "| AirAsia| I5-764|      Delhi| Early_Morning| zero|Early_Morning|          Mumbai|Economy|    null|        1| 5956|\n",
      "| Vistara| UK-995|      Delhi|       Morning| zero|    Afternoon|          Mumbai|Economy|    null|        1| 5955|\n",
      "| Vistara| UK-963|      Delhi|       Morning| zero|      Morning|          Mumbai|Economy|    null|        1| 5955|\n",
      "+--------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('airline', 'string'),\n",
       " ('flight', 'string'),\n",
       " ('source_city', 'string'),\n",
       " ('departure_time', 'string'),\n",
       " ('stops', 'string'),\n",
       " ('arrival_time', 'string'),\n",
       " ('destination_city', 'string'),\n",
       " ('class', 'string'),\n",
       " ('duration', 'int'),\n",
       " ('days_left', 'int'),\n",
       " ('price', 'int')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight_schema = StructType([StructField(\"airline\", StringType(), True), StructField(\"flight\", StringType(), True), \\\n",
    "                            StructField(\"source_city\", StringType(), True), StructField(\"departure_time\", StringType(), True), \\\n",
    "                            StructField(\"stops\", StringType(), True), StructField(\"arrival_time\", StringType(), True), \\\n",
    "                            StructField(\"destination_city\", StringType(), True), StructField(\"class\", StringType(), True), \\\n",
    "                            StructField(\"duration\", IntegerType(), True), StructField(\"days_left\", IntegerType(), True), StructField(\"price\", IntegerType(), True)])\n",
    "\n",
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"False\").schema(flight_schema).load(\"/home/manish/Documents/VSCodeProjects/Spark-Functions/SampleData/flight_data.csv\")\n",
    "df.show(5)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|  airline|toal_price|\n",
      "+---------+----------+\n",
      "|   Indigo| 229580207|\n",
      "| SpiceJet|  55681482|\n",
      "|Air_India|1901529790|\n",
      "|  AirAsia|  65858089|\n",
      "| GO_FIRST| 130973972|\n",
      "|  Vistara|3886552320|\n",
      "+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as Fun\n",
    "\n",
    "df_1 = df.groupBy(\"airline\").agg(Fun.sum(\"price\").alias(\"toal_price\"))\n",
    "df_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|airline|total_price|\n",
      "+-------+-----------+\n",
      "|AirAsia|   14205456|\n",
      "|AirAsia|   14205456|\n",
      "|AirAsia|   14205456|\n",
      "|AirAsia|   14205456|\n",
      "|AirAsia|   14205456|\n",
      "+-------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as Fun\n",
    "\n",
    "window_fun = Window.partitionBy(\"airline\").orderBy(\"source_city\")\n",
    "df_2 = df.select(df.airline, Fun.sum(\"price\").over(window_fun).alias(\"total_price\"))\n",
    "df_2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
